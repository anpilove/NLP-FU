{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff4c6970-4dfe-49e1-a03d-e83feb71b8f2",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4 Генерация текстов на основе LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0162e7f-0a4f-460a-a658-beee41050a26",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162ed30-d309-4042-b496-503f59a1e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7df70-31e9-44c4-a866-3be622cabb6b",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83fc142-6cf4-4ea7-bdef-00bba73cfb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    print(mps_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ccbd2-63cb-45ae-8460-68fa8d4e341b",
   "metadata": {},
   "source": [
    "## Функция обучение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e460a-5990-4a3c-9125-a06cb067b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, crterion, optimizer , n_epochs, train_loader):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in tqdm(train_loader , desc=f'Training epoch {epoch + 1}:'):\n",
    "            inputs = batch['input']\n",
    "            labels = batch['label']\n",
    "            print(inputs.dtype, inputs.shape)\n",
    "            output = model(inputs)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549c3b9-175c-4388-890d-5afd248f83e4",
   "metadata": {},
   "source": [
    "## Задание 1. Загрузите текст из произведений Ницше \n",
    "('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt').\n",
    "\n",
    "\n",
    "Выведете следующее:\n",
    "- А) длину всего корпуса;\n",
    "- Б) количество предложений;\n",
    "- В) сколько всего символов используется?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fedd06-1c95-4fab-9867-b2a5cef5dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nietzsche.txt', 'r') as file:\n",
    "    lines = file.read()\n",
    "\n",
    "text_nietzsche = lines\n",
    "text_nietzsche[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cdda4f-6df8-4daa-890f-68ae3d49f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nietzsche = text_nietzsche.lower()\n",
    "text_nietzsche = re.sub(r'\\s', ' ', text_nietzsche) # replace \\n \\t and etc.\n",
    "text_nietzsche = re.sub(r'\\s{2,}', ' ', text_nietzsche) # replace repeated whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394b475-5588-4188-bfb4-0d91109419c8",
   "metadata": {},
   "source": [
    "### Длина всего корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abaaad-9089-4f32-9acf-27eb918572d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_nietzsche)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e961e-91f5-46eb-83ac-8ebe237beb51",
   "metadata": {},
   "source": [
    "### Количество предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57505d77-fb01-451b-ba01-850300f47f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent_tokenize(text_nietzsche))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d225bef4-68c7-48dc-afc9-babde242adf1",
   "metadata": {},
   "source": [
    "### Cколько всего символов используется?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a402b-8279-4248-b92a-19cd77ac1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(text_nietzsche))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19556e4a-5485-46cb-be32-8d77a8708c28",
   "metadata": {},
   "source": [
    "## Задание 2. Сократите текст наполовину избыточными последовательностями символов maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513d05e-1d91-4c4c-b636-bda1ff0d7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(text_nietzsche, specials=[\"<unk>\"])\n",
    "token2inx = vocab.get_stoi()\n",
    "inx2token = {inx: token for token, inx in vocab.get_stoi().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd10674-336f-4de8-97b5-ac3b06befa20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token2inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbca9964-b64e-4348-8dfc-c9586b955957",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text_nietzsche) - maxlen, step):\n",
    "    sentences.append(text_nietzsche[i: i + maxlen])\n",
    "    next_chars.append(text_nietzsche[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(token2inx)))\n",
    "y = np.zeros((len(sentences), len(token2inx)))\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, token2inx[char]] = 1\n",
    "    y[i, token2inx[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e47d0b-bb48-4d06-b33f-e34669eb629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a9d2a-7e4e-48eb-bea0-4762735e6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67059a-514f-48e2-ad08-3bfa805e03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770737ac-b84d-4b37-ab3c-66259114f415",
   "metadata": {},
   "source": [
    "У нас в датасете 199607 40 символьных отрезков и ответ следущая буква. В каждом sample 40 списков one-hot, где одна единица обозначает букву."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f2848-5340-4b99-a9be-0e9022b289cd",
   "metadata": {},
   "source": [
    "## Задание 3. Создайте модель LSTM для генерации текста. \n",
    "\n",
    "- А) Напишите вспомогательную функцию для выборки индекса из массива вероятностей\n",
    "- Б) Напишите функцию, которая будет вызываться в конце каждой эпохи и печатать сгенерированный текст\n",
    "- В) Запустите модель на обучение Имейте ввиду, что требуется не менее 20 эпох, прежде чем сгенерированный текст начнет звучать связно. Рекомендуется запускать этот скрипт на графическом процессоре, так как рекуррентные сети требуют довольно больших вычислительных затрат.\n",
    "- Г) Проверьте работу модели в онлайн режиме."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b090df6-7b4e-4465-a067-30c93e028c7a",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e4592-ef61-4af2-ae2f-cfd63f6e909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(x,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8eb00-d3ee-42f8-b3f5-e91f0a76c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train) , len(X_test) , len(y_train) , len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ac2dd-fcc1-48a7-bcab-9aa061e644a3",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc5d51-3b5a-463b-96da-3c648244b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = torch.LongTensor(self.data[idx]).to(mps_device)\n",
    "        label = torch.LongTensor(self.labels[idx]).to(mps_device)\n",
    "        sample = {'input': input, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14b28e-fc2a-41f8-947b-d87c685a12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= CustomDataset(X_train, y_train)\n",
    "\n",
    "test_dataset= CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a88728-a76c-463a-b0a3-7bdbf7f6ca6b",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ab1b7-4d8c-4975-8d42-3a66a5302370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,  batch_size=256)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d50fa-a267-48e6-bd57-a88af58b3969",
   "metadata": {},
   "source": [
    "### Функция выборки индекса из массива вероятностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300413d-a3d1-424f-8c4c-569d2867133b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "786fb4b3-b960-4f6f-bc54-e96dc7968463",
   "metadata": {},
   "source": [
    "### Функция для генерации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a9810-c38f-47c5-82f9-3fdce2fb6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e448f-ecef-4bff-9fd0-39c19a1c63f5",
   "metadata": {},
   "source": [
    "### Модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971d088-c278-47aa-8b64-6d09bc854010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnpilovGpt(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size1, hidden_size2 ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings = vocab_size, embedding_dim = embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size1, batch_first=True) # (batch_size, seq_len, input_size)\n",
    "        self.linear = nn.Linear(in_features = hidden_size1 , out_features = hidden_size2 )\n",
    "        self.projection = nn.Linear(in_features = hidden_size2 , out_features = vocab_size) # vocab_size = num_classes\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 0.1) # defult p = 0.5\n",
    "        self.tanh = nn.Tanh() # against vanish gradient\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.embedding(input).view(256, 40, -1)\n",
    "        print(x.shape)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.projection(x)\n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caafc1e-428c-4a15-9e6d-31d51e3bf169",
   "metadata": {},
   "source": [
    "### Проверка модели на свой текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cec251-7163-4e6b-9a25-7cda551c2d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8cc20e2-3c88-47b2-84f9-ed8205982ac3",
   "metadata": {},
   "source": [
    "### Обучение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321c365-b365-4527-bf95-4caa42f1fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "vocab_size = len(vocab) # 57\n",
    "embedding_dim = 200\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 256\n",
    "\n",
    "\n",
    "model = AnpilovGpt(vocab_size, embedding_dim, hidden_size1, hidden_size2).to(mps_device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters()) # lr = 0.001\n",
    "\n",
    "train(model, criterion, optimizer, n_epochs, train_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d28e0ab2-0df6-4a0d-9b85-84eb64a66f6c",
   "metadata": {},
   "source": [
    "## Задание 4. Создайте самостоятельно генерацию текста для РУССКОЯЗЫЧНОГО НАБОРА глав Wikibooks.\r\n",
    "Полный текст Wikibooks содержит более 270000 глав на 12 языках https://www.kaggle.com/datasets/dhruvildave/wikibooks-dataset/data\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118b0f1-eae4-4e5e-a6d6-03e94e544971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
